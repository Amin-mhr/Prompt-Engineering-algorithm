package main

import (
	"bufio"
	"flag"
	"fmt"
	"os"
	"strings"
	"time"

	"Prompt_Engineering_algorithm/llm"
	"Prompt_Engineering_algorithm/prompts"
)

func main() {
	// Flags
	method := flag.String("method", "zero-shot", "prompting method: zero-shot | cot | few-shot | adihq")
	model := flag.String("model", "gpt-4o-mini", "LLM model name")
	temperature := flag.Float64("temperature", 0.0, "sampling temperature (0.0 - 2.0)")
	questionFlag := flag.String("question", "", "question text (if empty, read from stdin)")
	flag.Parse()

	// Read question
	var question string
	if q := strings.TrimSpace(*questionFlag); q != "" {
		question = q
	} else {
		reader := bufio.NewReader(os.Stdin)
		fmt.Print("â“ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ")
		q, _ := reader.ReadString('\n')
		question = strings.TrimSpace(q)
	}

	// Build prompt
	var prompt string
	switch *method {
	case "zero-shot":
		prompt = prompts.BuildZeroShotPrompt(question)
	case "cot":
		prompt = prompts.BuildCotPrompt(question)
	case "few-shot":
		prompt = prompts.BuildFewShotPrompt(question)
	case "ahdiq":
		prompt = prompts.BuildAdihqPrompt(question)
	default:
		fmt.Println("Ø±ÙˆØ´ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡! Ø§Ø² Ø¨ÛŒÙ†: zero-shot | cot | few-shot | adihq")
		return
	}

	// Call LLM
	start := time.Now()
	response, usage, err := llm.CallLLM(prompt, *model, float32(*temperature))
	elapsed := time.Since(start)
	if err != nil {
		fmt.Printf("âŒ Ø®Ø·Ø§: %v\n", err)
		return
	}

	// Output
	fmt.Println("\nğŸ”¹ Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„:")
	fmt.Println(response)

	fmt.Println("\nğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±Ø§Ù…Ù¾Øª:")
	fmt.Printf("Ù…Ø¯Ù„: %s | Ø±ÙˆØ´: %s | Ø¯Ù…Ø§: %.2f\n", *model, *method, *temperature)
	fmt.Printf("ØªÙˆÚ©Ù† ÙˆØ±ÙˆØ¯ÛŒ: %d\n", usage.PromptTokens)
	fmt.Printf("ØªÙˆÚ©Ù† Ø®Ø±ÙˆØ¬ÛŒ: %d\n", usage.CompletionTokens)
	fmt.Printf("Ú©Ù„ ØªÙˆÚ©Ù†: %d\n", usage.TotalTokens)
	fmt.Printf("Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®: %s\n", elapsed)
}
